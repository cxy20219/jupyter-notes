{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist分类任务：\n",
    "\n",
    "- 网络基本构建与训练方法，常用函数解析\n",
    "\n",
    "- torch.nn.functional模块\n",
    "\n",
    "- nn.Module模块\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取Mnist数据集\n",
    "- 会自动进行下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = \"../../../../datas/minist\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean = [0.5],std = [0.5])\n",
    "    ])\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = \"../../../../datas/minist\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "        transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean = [0.5],std = [0.5])\n",
    "    ])\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = np.array(train_data.data[0])\n",
    "plt.imshow(img,cmap=\"gray\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784是mnist数据集每个样本的像素点个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个model来简化代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 必须继承nn.Module且在其构造函数中需调用nn.Module的构造函数\n",
    "- 无需写反向传播函数，nn.Module能够利用autograd自动实现反向传播\n",
    "- Module中的可学习参数可以通过named_parameters()或者parameters()返回迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.model1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1,out_channels=64,kernel_size=3,stride=1,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(stride=2,kernel_size=2),\n",
    "        )\n",
    "        self.model2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(14*14*128,1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(1024, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        x = x.view(-1, 14*14*128)\n",
    "        x = self.model2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (model1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (model2): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以打印我们定义好名字里的权重和偏置项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1.0.weight Parameter containing:\n",
      "tensor([[[[-0.3319,  0.1322,  0.2586],\n",
      "          [-0.2581,  0.2516,  0.1719],\n",
      "          [ 0.3214, -0.1892,  0.1845]]],\n",
      "\n",
      "\n",
      "        [[[-0.2846,  0.0054,  0.0674],\n",
      "          [ 0.1867,  0.1668, -0.2712],\n",
      "          [ 0.2959, -0.0673,  0.3141]]],\n",
      "\n",
      "\n",
      "        [[[-0.0762,  0.0697, -0.2629],\n",
      "          [-0.2321,  0.3319,  0.0083],\n",
      "          [ 0.0552,  0.3173,  0.2354]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1740, -0.1064,  0.3242],\n",
      "          [ 0.0280,  0.0231,  0.2484],\n",
      "          [ 0.2695,  0.2927, -0.1349]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2785,  0.2296, -0.2079],\n",
      "          [-0.0723,  0.0534,  0.2601],\n",
      "          [-0.2272,  0.2131, -0.1736]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2924, -0.1593,  0.3127],\n",
      "          [ 0.2264, -0.2281, -0.2812],\n",
      "          [ 0.3004, -0.1223,  0.2428]]],\n",
      "\n",
      "\n",
      "        [[[-0.0025,  0.0774,  0.1458],\n",
      "          [-0.0057, -0.0682, -0.3179],\n",
      "          [-0.0404, -0.2575,  0.2684]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1210, -0.0017,  0.1847],\n",
      "          [ 0.2671, -0.2817, -0.1239],\n",
      "          [ 0.1921, -0.0618, -0.2144]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1794, -0.1921, -0.2731],\n",
      "          [-0.1556, -0.2034, -0.2141],\n",
      "          [-0.2318,  0.2923,  0.1688]]],\n",
      "\n",
      "\n",
      "        [[[-0.0308,  0.2578,  0.3295],\n",
      "          [-0.2644, -0.3297,  0.1823],\n",
      "          [-0.3143,  0.1208,  0.0399]]],\n",
      "\n",
      "\n",
      "        [[[-0.2767, -0.0805, -0.0016],\n",
      "          [ 0.2736, -0.2567,  0.0651],\n",
      "          [-0.2316,  0.0998, -0.2498]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2390,  0.2161, -0.0334],\n",
      "          [-0.2591,  0.3230, -0.1873],\n",
      "          [-0.2444, -0.3273, -0.0321]]],\n",
      "\n",
      "\n",
      "        [[[-0.2859, -0.0711,  0.1180],\n",
      "          [ 0.2167,  0.1596, -0.1751],\n",
      "          [ 0.0350, -0.2304, -0.3274]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0601,  0.1936, -0.3016],\n",
      "          [-0.1002, -0.2027, -0.2690],\n",
      "          [ 0.3025, -0.1705,  0.1323]]],\n",
      "\n",
      "\n",
      "        [[[-0.1890,  0.2966,  0.1562],\n",
      "          [-0.3176,  0.2168,  0.2119],\n",
      "          [ 0.1773, -0.0527, -0.2799]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0240, -0.1645, -0.2803],\n",
      "          [-0.0620, -0.1868,  0.0155],\n",
      "          [-0.1487,  0.1903, -0.3065]]],\n",
      "\n",
      "\n",
      "        [[[-0.0325,  0.3198,  0.3215],\n",
      "          [ 0.2782,  0.2659, -0.2956],\n",
      "          [-0.1858,  0.0573,  0.1437]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1889,  0.2970, -0.1206],\n",
      "          [-0.2740,  0.2961, -0.0491],\n",
      "          [ 0.1580,  0.2717, -0.0318]]],\n",
      "\n",
      "\n",
      "        [[[-0.2543, -0.2064, -0.2933],\n",
      "          [ 0.1294,  0.0428, -0.2911],\n",
      "          [-0.2749, -0.1924, -0.0582]]],\n",
      "\n",
      "\n",
      "        [[[-0.2248, -0.1384, -0.0667],\n",
      "          [ 0.2193, -0.1045, -0.2112],\n",
      "          [ 0.1034,  0.1374, -0.1456]]],\n",
      "\n",
      "\n",
      "        [[[-0.1619, -0.0034,  0.3301],\n",
      "          [ 0.2859, -0.0714, -0.0173],\n",
      "          [-0.1046, -0.1539, -0.1263]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0625, -0.0270,  0.0619],\n",
      "          [ 0.1713, -0.1063,  0.1645],\n",
      "          [ 0.2841,  0.1034, -0.1158]]],\n",
      "\n",
      "\n",
      "        [[[-0.2842,  0.2813,  0.2710],\n",
      "          [-0.0016, -0.1921,  0.2640],\n",
      "          [-0.1305,  0.0213, -0.1800]]],\n",
      "\n",
      "\n",
      "        [[[-0.1131, -0.3265, -0.2627],\n",
      "          [ 0.1543,  0.0070,  0.2695],\n",
      "          [ 0.1523, -0.1302, -0.2352]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2948,  0.2856,  0.2096],\n",
      "          [ 0.1052,  0.1494, -0.0917],\n",
      "          [ 0.1722,  0.1529, -0.0520]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2582,  0.0122,  0.0821],\n",
      "          [ 0.2934, -0.2098, -0.2769],\n",
      "          [-0.3193,  0.0810,  0.1017]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2028,  0.2713,  0.2138],\n",
      "          [-0.0144, -0.2892,  0.0973],\n",
      "          [-0.1952, -0.2069,  0.2291]]],\n",
      "\n",
      "\n",
      "        [[[-0.2408, -0.2990, -0.1612],\n",
      "          [-0.2371, -0.0719, -0.2325],\n",
      "          [ 0.1154,  0.1689, -0.0675]]],\n",
      "\n",
      "\n",
      "        [[[-0.0795,  0.0932, -0.2976],\n",
      "          [ 0.3088, -0.2325, -0.1599],\n",
      "          [-0.0901, -0.1887, -0.0884]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1319,  0.2616, -0.0220],\n",
      "          [-0.2171,  0.0925,  0.1876],\n",
      "          [ 0.2510, -0.1312,  0.1435]]],\n",
      "\n",
      "\n",
      "        [[[-0.2963, -0.3115,  0.2123],\n",
      "          [ 0.0215,  0.0812, -0.3021],\n",
      "          [ 0.1473, -0.2108,  0.0341]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3333,  0.1039,  0.0317],\n",
      "          [ 0.1150, -0.2964,  0.2596],\n",
      "          [-0.1778, -0.3027,  0.2205]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3159, -0.2831, -0.1486],\n",
      "          [ 0.2289,  0.0445,  0.0229],\n",
      "          [-0.2521,  0.3201, -0.1512]]],\n",
      "\n",
      "\n",
      "        [[[-0.0616,  0.1895, -0.2875],\n",
      "          [ 0.0028, -0.3054,  0.0537],\n",
      "          [ 0.0442, -0.1451, -0.0665]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2434,  0.0519,  0.0872],\n",
      "          [-0.1829,  0.1182, -0.1677],\n",
      "          [ 0.2357, -0.3130, -0.1702]]],\n",
      "\n",
      "\n",
      "        [[[-0.3328, -0.2664,  0.2775],\n",
      "          [-0.2891, -0.1243, -0.0436],\n",
      "          [-0.2025,  0.1596, -0.2353]]],\n",
      "\n",
      "\n",
      "        [[[-0.1995,  0.1990,  0.0668],\n",
      "          [ 0.1714, -0.0360, -0.1039],\n",
      "          [ 0.1797,  0.0603,  0.1479]]],\n",
      "\n",
      "\n",
      "        [[[-0.0247, -0.1929, -0.2412],\n",
      "          [ 0.2896,  0.2638, -0.3292],\n",
      "          [ 0.1800, -0.2238,  0.1953]]],\n",
      "\n",
      "\n",
      "        [[[-0.1932, -0.1105, -0.0474],\n",
      "          [-0.1063, -0.0969, -0.2817],\n",
      "          [ 0.0545,  0.2777, -0.0265]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0968, -0.0276,  0.1607],\n",
      "          [ 0.3073,  0.3308,  0.2826],\n",
      "          [ 0.2428,  0.2112,  0.2070]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0230, -0.0402, -0.1666],\n",
      "          [-0.1720,  0.1722, -0.0952],\n",
      "          [-0.2648,  0.0259,  0.0924]]],\n",
      "\n",
      "\n",
      "        [[[-0.1558,  0.0510, -0.0165],\n",
      "          [-0.0517, -0.1075, -0.1390],\n",
      "          [-0.1304, -0.1215,  0.1927]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3290,  0.1209, -0.2081],\n",
      "          [-0.1489,  0.2258,  0.2192],\n",
      "          [ 0.0601, -0.2138, -0.1462]]],\n",
      "\n",
      "\n",
      "        [[[-0.1992,  0.0244,  0.0950],\n",
      "          [-0.1626, -0.0422, -0.2713],\n",
      "          [-0.1062, -0.0616,  0.2151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2270, -0.0533, -0.2844],\n",
      "          [ 0.2969, -0.1592, -0.1279],\n",
      "          [ 0.2276, -0.0743,  0.1508]]],\n",
      "\n",
      "\n",
      "        [[[-0.0950, -0.1671,  0.2540],\n",
      "          [-0.0654, -0.0584,  0.1895],\n",
      "          [ 0.3292,  0.0593,  0.0366]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1630,  0.0385, -0.1048],\n",
      "          [-0.0644,  0.0851,  0.1938],\n",
      "          [ 0.1906,  0.0908,  0.1102]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1692, -0.2302, -0.1141],\n",
      "          [-0.1031,  0.1928,  0.2404],\n",
      "          [ 0.0670, -0.1001,  0.0543]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1444,  0.3134,  0.1776],\n",
      "          [ 0.0354,  0.2982, -0.0631],\n",
      "          [ 0.1808,  0.1943,  0.3263]]],\n",
      "\n",
      "\n",
      "        [[[-0.0129,  0.1576, -0.1589],\n",
      "          [ 0.0145, -0.2432,  0.1562],\n",
      "          [ 0.2815, -0.0355,  0.1482]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2150,  0.1373, -0.0684],\n",
      "          [-0.2605,  0.0633, -0.1811],\n",
      "          [-0.1615, -0.1458,  0.2320]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2951, -0.1391,  0.3045],\n",
      "          [-0.1658, -0.0908,  0.1511],\n",
      "          [ 0.1363, -0.3099,  0.1406]]],\n",
      "\n",
      "\n",
      "        [[[-0.0352,  0.0242,  0.1762],\n",
      "          [-0.1804,  0.2906,  0.2744],\n",
      "          [-0.3208,  0.3331, -0.1312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0071, -0.1511,  0.3084],\n",
      "          [-0.2330, -0.1683, -0.3054],\n",
      "          [-0.2231, -0.1339, -0.0656]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0553,  0.1430,  0.2975],\n",
      "          [-0.2636, -0.1435, -0.3294],\n",
      "          [ 0.1451,  0.1632,  0.0391]]],\n",
      "\n",
      "\n",
      "        [[[-0.1983,  0.1102, -0.0341],\n",
      "          [-0.2969, -0.0011,  0.2462],\n",
      "          [ 0.1588, -0.2668, -0.2776]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0247,  0.2759, -0.0443],\n",
      "          [-0.2629, -0.1642,  0.0488],\n",
      "          [-0.2329, -0.0083,  0.0619]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2045,  0.2651,  0.1035],\n",
      "          [-0.1255,  0.0046,  0.1644],\n",
      "          [ 0.1431,  0.0007, -0.0947]]],\n",
      "\n",
      "\n",
      "        [[[-0.1194, -0.2032, -0.0011],\n",
      "          [-0.1644,  0.0033,  0.1134],\n",
      "          [-0.0226, -0.3066,  0.3140]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3101,  0.2710, -0.2096],\n",
      "          [-0.0589, -0.0492, -0.2180],\n",
      "          [-0.1620,  0.2611,  0.1898]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0044, -0.1798, -0.0336],\n",
      "          [-0.1120, -0.0883,  0.2611],\n",
      "          [ 0.1955, -0.0298, -0.2123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1258, -0.0042, -0.0788],\n",
      "          [-0.1538, -0.2127,  0.2781],\n",
      "          [ 0.1422, -0.1037, -0.1490]]],\n",
      "\n",
      "\n",
      "        [[[-0.3260, -0.2455,  0.1601],\n",
      "          [ 0.1758,  0.2676,  0.1997],\n",
      "          [ 0.2310,  0.1030,  0.0085]]],\n",
      "\n",
      "\n",
      "        [[[-0.2899, -0.0333,  0.1509],\n",
      "          [ 0.1522,  0.0962, -0.0962],\n",
      "          [ 0.1180,  0.2974, -0.2435]]]], requires_grad=True) torch.Size([64, 1, 3, 3])\n",
      "model1.0.bias Parameter containing:\n",
      "tensor([ 0.0761,  0.0548, -0.3194, -0.2240, -0.1852, -0.3152, -0.2368, -0.2649,\n",
      "        -0.1531,  0.0881, -0.2672,  0.0097,  0.1195, -0.2676,  0.2522, -0.0166,\n",
      "         0.1731, -0.3231, -0.0830, -0.0038,  0.2609,  0.2162, -0.2226, -0.0695,\n",
      "         0.2973, -0.2267,  0.0661, -0.2993, -0.1969, -0.1920, -0.0824, -0.3164,\n",
      "        -0.1418,  0.0465, -0.0932,  0.0874, -0.0086, -0.1784,  0.3211, -0.2559,\n",
      "        -0.2369,  0.2954,  0.2315,  0.2010,  0.1669, -0.2086,  0.2522,  0.1074,\n",
      "         0.3292,  0.0053,  0.2313, -0.0355, -0.2931,  0.0471, -0.1052,  0.1193,\n",
      "         0.2491,  0.1965,  0.2115,  0.0454,  0.0174,  0.2331, -0.2212,  0.3079],\n",
      "       requires_grad=True) torch.Size([64])\n",
      "model1.2.weight Parameter containing:\n",
      "tensor([[[[ 0.0006, -0.0191,  0.0271],\n",
      "          [-0.0041, -0.0304, -0.0111],\n",
      "          [ 0.0071, -0.0024,  0.0022]],\n",
      "\n",
      "         [[-0.0040, -0.0009,  0.0416],\n",
      "          [ 0.0214, -0.0250,  0.0049],\n",
      "          [ 0.0315, -0.0092,  0.0034]],\n",
      "\n",
      "         [[-0.0333, -0.0062, -0.0390],\n",
      "          [ 0.0350,  0.0010,  0.0317],\n",
      "          [ 0.0063,  0.0252,  0.0382]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0402, -0.0088,  0.0284],\n",
      "          [-0.0146,  0.0153,  0.0017],\n",
      "          [ 0.0355, -0.0121,  0.0057]],\n",
      "\n",
      "         [[-0.0087,  0.0126,  0.0090],\n",
      "          [ 0.0206,  0.0320,  0.0265],\n",
      "          [-0.0297,  0.0258, -0.0323]],\n",
      "\n",
      "         [[ 0.0222,  0.0305,  0.0271],\n",
      "          [-0.0280, -0.0409,  0.0261],\n",
      "          [-0.0342,  0.0153, -0.0118]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0255, -0.0119, -0.0037],\n",
      "          [ 0.0399,  0.0258,  0.0058],\n",
      "          [ 0.0322,  0.0256,  0.0277]],\n",
      "\n",
      "         [[ 0.0070, -0.0172, -0.0125],\n",
      "          [ 0.0217,  0.0180, -0.0296],\n",
      "          [ 0.0299, -0.0088, -0.0293]],\n",
      "\n",
      "         [[ 0.0202, -0.0243,  0.0002],\n",
      "          [-0.0410, -0.0136,  0.0171],\n",
      "          [-0.0366, -0.0393, -0.0232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0145,  0.0388, -0.0195],\n",
      "          [-0.0264,  0.0300,  0.0316],\n",
      "          [-0.0319,  0.0155, -0.0286]],\n",
      "\n",
      "         [[-0.0049,  0.0375,  0.0159],\n",
      "          [ 0.0117, -0.0329, -0.0216],\n",
      "          [-0.0048,  0.0360,  0.0364]],\n",
      "\n",
      "         [[-0.0071, -0.0060,  0.0273],\n",
      "          [ 0.0169, -0.0004,  0.0237],\n",
      "          [-0.0127, -0.0164, -0.0092]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0024, -0.0338,  0.0324],\n",
      "          [ 0.0193,  0.0067, -0.0145],\n",
      "          [-0.0293,  0.0413, -0.0209]],\n",
      "\n",
      "         [[ 0.0398,  0.0020,  0.0361],\n",
      "          [-0.0111, -0.0311, -0.0289],\n",
      "          [ 0.0300,  0.0318, -0.0115]],\n",
      "\n",
      "         [[-0.0049, -0.0226, -0.0024],\n",
      "          [ 0.0323,  0.0240,  0.0405],\n",
      "          [-0.0276,  0.0038,  0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0047,  0.0247,  0.0122],\n",
      "          [-0.0261, -0.0288, -0.0115],\n",
      "          [-0.0397, -0.0213, -0.0139]],\n",
      "\n",
      "         [[-0.0020, -0.0327, -0.0370],\n",
      "          [ 0.0299, -0.0039, -0.0228],\n",
      "          [ 0.0266,  0.0128,  0.0292]],\n",
      "\n",
      "         [[ 0.0252,  0.0144,  0.0143],\n",
      "          [ 0.0326, -0.0342, -0.0138],\n",
      "          [ 0.0131,  0.0021,  0.0190]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0291,  0.0289, -0.0327],\n",
      "          [-0.0002,  0.0203,  0.0268],\n",
      "          [ 0.0024, -0.0040, -0.0385]],\n",
      "\n",
      "         [[ 0.0052, -0.0347, -0.0155],\n",
      "          [-0.0192,  0.0034, -0.0361],\n",
      "          [ 0.0015,  0.0178,  0.0158]],\n",
      "\n",
      "         [[ 0.0047, -0.0090,  0.0035],\n",
      "          [ 0.0053, -0.0263, -0.0195],\n",
      "          [-0.0250, -0.0306, -0.0154]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0005,  0.0321, -0.0370],\n",
      "          [ 0.0043,  0.0362, -0.0038],\n",
      "          [-0.0159, -0.0282, -0.0247]],\n",
      "\n",
      "         [[ 0.0407,  0.0010, -0.0040],\n",
      "          [ 0.0401, -0.0392, -0.0025],\n",
      "          [ 0.0367,  0.0252, -0.0242]],\n",
      "\n",
      "         [[ 0.0238,  0.0291, -0.0192],\n",
      "          [ 0.0181, -0.0190,  0.0343],\n",
      "          [ 0.0303,  0.0115, -0.0310]]],\n",
      "\n",
      "\n",
      "        [[[-0.0066, -0.0310,  0.0028],\n",
      "          [ 0.0163, -0.0332, -0.0131],\n",
      "          [ 0.0143, -0.0216,  0.0244]],\n",
      "\n",
      "         [[ 0.0033, -0.0300, -0.0369],\n",
      "          [ 0.0041, -0.0039,  0.0304],\n",
      "          [ 0.0331,  0.0027, -0.0360]],\n",
      "\n",
      "         [[-0.0191,  0.0126, -0.0244],\n",
      "          [ 0.0049,  0.0301, -0.0172],\n",
      "          [-0.0378, -0.0104, -0.0127]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0110,  0.0130,  0.0114],\n",
      "          [ 0.0277,  0.0388, -0.0221],\n",
      "          [-0.0166,  0.0257, -0.0259]],\n",
      "\n",
      "         [[ 0.0095, -0.0047, -0.0348],\n",
      "          [-0.0281, -0.0123,  0.0106],\n",
      "          [ 0.0138,  0.0228,  0.0331]],\n",
      "\n",
      "         [[-0.0338, -0.0405, -0.0345],\n",
      "          [ 0.0370,  0.0043,  0.0112],\n",
      "          [ 0.0326,  0.0199,  0.0103]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0053,  0.0288,  0.0311],\n",
      "          [-0.0405, -0.0395,  0.0335],\n",
      "          [-0.0225,  0.0321, -0.0392]],\n",
      "\n",
      "         [[-0.0232,  0.0168,  0.0319],\n",
      "          [-0.0403,  0.0350,  0.0254],\n",
      "          [-0.0008,  0.0187,  0.0030]],\n",
      "\n",
      "         [[ 0.0237,  0.0380,  0.0299],\n",
      "          [ 0.0041,  0.0030, -0.0041],\n",
      "          [-0.0144,  0.0239, -0.0344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0394, -0.0217, -0.0325],\n",
      "          [ 0.0392,  0.0358,  0.0040],\n",
      "          [ 0.0399, -0.0333,  0.0305]],\n",
      "\n",
      "         [[-0.0361,  0.0012,  0.0058],\n",
      "          [-0.0182, -0.0326, -0.0260],\n",
      "          [-0.0204, -0.0138,  0.0134]],\n",
      "\n",
      "         [[-0.0161,  0.0403,  0.0223],\n",
      "          [ 0.0257, -0.0300, -0.0229],\n",
      "          [ 0.0068,  0.0182, -0.0126]]]], requires_grad=True) torch.Size([128, 64, 3, 3])\n",
      "model1.2.bias Parameter containing:\n",
      "tensor([-0.0104,  0.0205, -0.0138,  0.0264, -0.0193, -0.0002,  0.0050,  0.0226,\n",
      "        -0.0389,  0.0245, -0.0255,  0.0169, -0.0107, -0.0284,  0.0118, -0.0236,\n",
      "        -0.0316, -0.0365, -0.0028,  0.0151,  0.0165, -0.0401, -0.0001, -0.0101,\n",
      "        -0.0030,  0.0177,  0.0036,  0.0195, -0.0151, -0.0181,  0.0155,  0.0129,\n",
      "        -0.0411, -0.0366, -0.0300, -0.0031, -0.0399,  0.0399,  0.0227, -0.0376,\n",
      "        -0.0159, -0.0215, -0.0348, -0.0115, -0.0147, -0.0070, -0.0052, -0.0260,\n",
      "        -0.0305, -0.0070, -0.0303,  0.0232, -0.0019,  0.0048,  0.0410,  0.0089,\n",
      "        -0.0182,  0.0321, -0.0186,  0.0399, -0.0241, -0.0083,  0.0204, -0.0269,\n",
      "         0.0279,  0.0219,  0.0099, -0.0325, -0.0222, -0.0344,  0.0268, -0.0230,\n",
      "        -0.0397,  0.0325,  0.0260,  0.0105, -0.0071,  0.0006,  0.0212, -0.0109,\n",
      "         0.0059, -0.0187, -0.0236, -0.0137,  0.0036, -0.0169, -0.0258,  0.0010,\n",
      "         0.0022, -0.0297, -0.0377,  0.0057,  0.0137, -0.0098,  0.0197,  0.0096,\n",
      "         0.0366,  0.0156,  0.0198,  0.0405,  0.0337,  0.0014,  0.0366,  0.0073,\n",
      "         0.0198,  0.0397, -0.0182, -0.0416,  0.0074, -0.0311,  0.0152,  0.0038,\n",
      "        -0.0393,  0.0117,  0.0070,  0.0337,  0.0305, -0.0208, -0.0231,  0.0249,\n",
      "         0.0397, -0.0098,  0.0052,  0.0166,  0.0228, -0.0168,  0.0078, -0.0401],\n",
      "       requires_grad=True) torch.Size([128])\n",
      "model2.0.weight Parameter containing:\n",
      "tensor([[-2.2868e-03,  5.5361e-03, -1.0517e-03,  ...,  5.5575e-03,\n",
      "          3.7919e-03,  2.8035e-03],\n",
      "        [-1.4145e-03, -3.8804e-04, -5.6277e-03,  ..., -1.3932e-03,\n",
      "          1.1551e-03, -1.2599e-03],\n",
      "        [-4.9872e-03, -5.3118e-03, -5.3963e-03,  ...,  6.0062e-03,\n",
      "         -2.1013e-03,  3.2303e-03],\n",
      "        ...,\n",
      "        [-3.2776e-03,  4.9484e-03, -4.3642e-03,  ..., -6.9892e-04,\n",
      "          8.5693e-05,  3.8476e-03],\n",
      "        [-2.4888e-03, -6.1357e-03,  3.2634e-03,  ..., -3.5899e-04,\n",
      "         -2.4721e-03,  3.7265e-03],\n",
      "        [ 2.3526e-04,  2.3292e-03,  2.2429e-03,  ..., -5.6507e-03,\n",
      "          2.9933e-03,  4.9674e-03]], requires_grad=True) torch.Size([1024, 25088])\n",
      "model2.0.bias Parameter containing:\n",
      "tensor([-0.0018,  0.0056, -0.0055,  ..., -0.0046, -0.0017,  0.0042],\n",
      "       requires_grad=True) torch.Size([1024])\n",
      "model2.3.weight Parameter containing:\n",
      "tensor([[ 0.0229,  0.0086, -0.0051,  ..., -0.0044, -0.0129,  0.0283],\n",
      "        [-0.0112, -0.0209, -0.0261,  ..., -0.0084, -0.0199, -0.0255],\n",
      "        [-0.0084, -0.0086, -0.0122,  ...,  0.0071, -0.0190,  0.0116],\n",
      "        ...,\n",
      "        [ 0.0206, -0.0111, -0.0108,  ...,  0.0100,  0.0077,  0.0192],\n",
      "        [-0.0153,  0.0285, -0.0141,  ...,  0.0039, -0.0046, -0.0295],\n",
      "        [-0.0023,  0.0058, -0.0031,  ..., -0.0099, -0.0103,  0.0198]],\n",
      "       requires_grad=True) torch.Size([10, 1024])\n",
      "model2.3.bias Parameter containing:\n",
      "tensor([ 0.0270, -0.0268, -0.0248,  0.0131, -0.0285, -0.0269, -0.0127, -0.0098,\n",
      "         0.0206, -0.0037], requires_grad=True) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in model.named_parameters():\n",
    "    print(name, parameter,parameter.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用TensorDataset和DataLoader来简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# train_data = TensorDataset(train_data.data, train_data.targets)\n",
    "train_load = DataLoader(train_data, batch_size=64,num_workers=4,pin_memory=True, shuffle=True)\n",
    "\n",
    "# test_data = TensorDataset(test_data.data, test_data.targets)\n",
    "test_load = DataLoader(test_data,num_workers=4,pin_memory=True,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epoch = 5\n",
    "test_data_size = len(test_data)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model()\n",
    "model.to(device)\n",
    "loss_fn.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一般在训练模型时加上model.train()，这样会正常使用Batch Normalization和 Dropout\n",
    "- 测试的时候一般选择model.eval()，这样就不会使用Batch Normalization和 Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------第1轮训练开始------------\n",
      "训练轮数：0,loss:0.3388301730155945\n",
      "整体测试集上的loss:21.92917632125318\n",
      "整体测试集上的正确率:0.9594999551773071\n",
      "-------------第2轮训练开始------------\n",
      "训练轮数：1,loss:0.018558554351329803\n",
      "整体测试集上的loss:19.725693436339498\n",
      "整体测试集上的正确率:0.9610999822616577\n",
      "-------------第3轮训练开始------------\n",
      "训练轮数：2,loss:0.5019228458404541\n",
      "整体测试集上的loss:18.44894193392247\n",
      "整体测试集上的正确率:0.9634999632835388\n",
      "-------------第4轮训练开始------------\n",
      "训练轮数：3,loss:0.2557317912578583\n",
      "整体测试集上的loss:20.41144162652199\n",
      "整体测试集上的正确率:0.9617999792098999\n",
      "-------------第5轮训练开始------------\n",
      "训练轮数：4,loss:0.39774876832962036\n",
      "整体测试集上的loss:19.16067609115271\n",
      "整体测试集上的正确率:0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    print(\"-------------第{}轮训练开始------------\".format(i+1))\n",
    "    # 训练步骤开始\n",
    "    model.train()\n",
    "    for data in train_load:\n",
    "        imgs,targets = data\n",
    "        imgs = imgs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "        \n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"训练轮数：{},loss:{}\".format(i,loss.item()))\n",
    "        \n",
    "    # 测试步骤\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_load:\n",
    "            imgs,targets = data\n",
    "            imgs = imgs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            total_test_loss += loss.item()\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()\n",
    "            total_accuracy+=accuracy\n",
    "    print(\"整体测试集上的loss:{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率:{}\".format(total_accuracy/test_data_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('AI')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "edff09c04b0b8f151f1a23da0f1d81b4651050c2abc772ada3fce2895b2777a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
